{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2QR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "917d84f3a7394f86857bea6eb84fd8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6604f7ec06649f09465b5525a60c386",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6e686a8998004f02ad2afb4a082766bf",
              "IPY_MODEL_899b10e196e347808e526740cf6f73e2"
            ]
          }
        },
        "c6604f7ec06649f09465b5525a60c386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e686a8998004f02ad2afb4a082766bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8d341a083980461a8d8b09fd9479e62f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e9045a8bf86409eb62973dffee9288a"
          }
        },
        "899b10e196e347808e526740cf6f73e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77807a1628b342e2a262d80643144c75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:01&lt;00:00, 974kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_babb898645a04d65ace72e3d078efe48"
          }
        },
        "8d341a083980461a8d8b09fd9479e62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e9045a8bf86409eb62973dffee9288a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77807a1628b342e2a262d80643144c75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "babb898645a04d65ace72e3d078efe48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dce69c697dbc4aea83b48fcf96e9557a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1336acfff9c40a594bc6b5bd0331494",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23d5e803b695412f9cd88ab8deba0112",
              "IPY_MODEL_58fd2b9a83f94a318a8ce544a04516d5"
            ]
          }
        },
        "b1336acfff9c40a594bc6b5bd0331494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23d5e803b695412f9cd88ab8deba0112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f280cbd6298b4333b62bdf271bb560f7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82a15d53c7ed4fec95a49dbe08eb5322"
          }
        },
        "58fd2b9a83f94a318a8ce544a04516d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6940ec2221424003b6918ddcc38d3f9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 960kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0800dd1a62a945cca606a155e8d4f531"
          }
        },
        "f280cbd6298b4333b62bdf271bb560f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82a15d53c7ed4fec95a49dbe08eb5322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6940ec2221424003b6918ddcc38d3f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0800dd1a62a945cca606a155e8d4f531": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3655df07392846be955c611fd94146c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_24465b9bcc394ad884faca1203e588d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_857094b2c583478abf2226e8faf2bf70",
              "IPY_MODEL_249eb48faa38443b8ef54e26779bd388"
            ]
          }
        },
        "24465b9bcc394ad884faca1203e588d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "857094b2c583478abf2226e8faf2bf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9b8d0cb601d54d86a263ab68d2f4a111",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35892c8a172240a39f4d50ccd3d43cca"
          }
        },
        "249eb48faa38443b8ef54e26779bd388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_117d0cb0d8fb4e7687b47e2abf945b26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 2.25kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0dd29a02dd524fcba66329dcd3872d5e"
          }
        },
        "9b8d0cb601d54d86a263ab68d2f4a111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35892c8a172240a39f4d50ccd3d43cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "117d0cb0d8fb4e7687b47e2abf945b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0dd29a02dd524fcba66329dcd3872d5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f85b843e20424b28918363caae3125b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63f90ba190d44425b6d99b91aa45e4d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8175eb5a7d14928b69a676c1868d6ea",
              "IPY_MODEL_0fc2bb97427a4867bb74ca64b2f25599"
            ]
          }
        },
        "63f90ba190d44425b6d99b91aa45e4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8175eb5a7d14928b69a676c1868d6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2537b58417e143cdb772ccb38ef1ba31",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9648c544629c4483b88aac73209dd36b"
          }
        },
        "0fc2bb97427a4867bb74ca64b2f25599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa3086cc29b84a479e3bb187003434ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:07&lt;00:00, 73.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc5b4bea734547c4a5218d9887840f84"
          }
        },
        "2537b58417e143cdb772ccb38ef1ba31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9648c544629c4483b88aac73209dd36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa3086cc29b84a479e3bb187003434ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc5b4bea734547c4a5218d9887840f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKEbOXIapRNZ"
      },
      "source": [
        "This script contains an implementation of GPT-2-small used for Question Reformulation. In this notebook the dataset QReCC is loaded and the GPT-2 model is trained on the dataset using a cross-entropy loss. Additional tokens are added to GPT-2's tokenizer and thereby need to be learnt in the word embedding matrix. The last hidden state of GPT-2 is then multipled by the word embedding matrix and a SoftMax is applied to select the next token. During training all tokens excepts those in the target re-written sentence of QReCC are masked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa3ICcx6pLdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9def63b1-bf34-4448-fca6-ad5b003e6e09"
      },
      "source": [
        "%%shell\n",
        "#wget  https://obj.umiacs.umd.edu/elgohary/CANARD_Release.zip\n",
        "#unzip CANARD_Release.zip\n",
        "wget https://github.com/apple/ml-qrecc/blob/main/dataset/qrecc_data.zip?raw=true\n",
        "unzip qrecc_data.zip?raw=true\n",
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-09 04:09:56--  https://github.com/apple/ml-qrecc/blob/main/dataset/qrecc_data.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/apple/ml-qrecc/raw/main/dataset/qrecc_data.zip [following]\n",
            "--2020-12-09 04:09:56--  https://github.com/apple/ml-qrecc/raw/main/dataset/qrecc_data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/apple/ml-qrecc/main/dataset/qrecc_data.zip [following]\n",
            "--2020-12-09 04:09:57--  https://raw.githubusercontent.com/apple/ml-qrecc/main/dataset/qrecc_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7925044 (7.6M) [application/zip]\n",
            "Saving to: ‘qrecc_data.zip?raw=true’\n",
            "\n",
            "qrecc_data.zip?raw= 100%[===================>]   7.56M  48.1MB/s    in 0.2s    \n",
            "\n",
            "2020-12-09 04:09:57 (48.1 MB/s) - ‘qrecc_data.zip?raw=true’ saved [7925044/7925044]\n",
            "\n",
            "Archive:  qrecc_data.zip?raw=true\n",
            "  inflating: qrecc_train.json        \n",
            "  inflating: qrecc_test.json         \n",
            "  inflating: __MACOSX/._qrecc_test.json  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InEIg8-KpfGA"
      },
      "source": [
        "import json\n",
        "with open('qrecc_train.json') as f:\n",
        "  train_file = json.load(f)\n",
        "with open('qrecc_test.json') as f:\n",
        "  val_file = json.load(f) #Conversation_no"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3J-hoWyE3pd"
      },
      "source": [
        "def format_data(file, dialog_id):\n",
        "  '''\n",
        "  input file: the json data to format for GPT-2 to fine-tune on.\n",
        "  input dialog_id: Identifier to each dialog sequence. This is to ensure proper formatting.   \n",
        "  '''\n",
        "  id = 'init'\n",
        "  x_data = {}\n",
        "  y_data = {}\n",
        "  # idx will point a first question to begin\n",
        "  for sample in file: \n",
        "    if id != sample[dialog_id]: #  initialize new conversation\n",
        "      # TRY ADDING MORE CONVERSATIONAL IN THE STARTING QUESTION OTHERWISE IMPOSSIBLE AND THESE ARE NOT ANSWERABLE\n",
        "      id = sample[dialog_id]\n",
        "      x_data[id] = ['<|startoftext|>' + sample['Question'] + '<|go|>' + sample['Rewrite'] + '<|endoftext|>']\n",
        "      y_data[id] = [sample['Rewrite']]\n",
        "      idx = 1\n",
        "    else:\n",
        "      x_data[id] += ['<|startoftext|>' + '<|sep|>'.join(y_data[id][:idx] + [sample['Question']]) + '<|go|>' + sample['Rewrite'] + '<|endoftext|>'] # [previous_rewritten_Qs] + [new_Q]\n",
        "      y_data[id] += [sample['Rewrite']]\n",
        "      idx += 1\n",
        "\n",
        "  # TRY SKIPPING SOME OF THE FIRST SAMPLES LATER TO SEE IF THEY ARE JUST INDUCING NOISE INTO THE PROBLEM \n",
        "  x_text = [t for text in x_data.values() for t in text]\n",
        "  y_text = [t for text in y_data.values() for t in text]\n",
        "\n",
        "  return x_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT9d__yb3knb"
      },
      "source": [
        "dialog_id = 'Conversation_no'\n",
        "train_text = format_data(train_file, dialog_id)\n",
        "val_text = format_data(val_file, dialog_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN7zOyPF6TgF",
        "outputId": "9c8429db-82f3-4836-f3cf-825fa95eddf8"
      },
      "source": [
        "count = 0\n",
        "for samp in train_text:\n",
        "  count+= len(samp.split())\n",
        "print('The estimate of the number of tokens on average is {}'.format(count / len(train_text)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The estimate of the number of tokens on average is 41.53488921434308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQdxjlRLqML_"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel,GPT2Config\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmFeU7Yr-DIj"
      },
      "source": [
        "#### Load tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmAawoeF1QuB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "917d84f3a7394f86857bea6eb84fd8dc",
            "c6604f7ec06649f09465b5525a60c386",
            "6e686a8998004f02ad2afb4a082766bf",
            "899b10e196e347808e526740cf6f73e2",
            "8d341a083980461a8d8b09fd9479e62f",
            "2e9045a8bf86409eb62973dffee9288a",
            "77807a1628b342e2a262d80643144c75",
            "babb898645a04d65ace72e3d078efe48",
            "dce69c697dbc4aea83b48fcf96e9557a",
            "b1336acfff9c40a594bc6b5bd0331494",
            "23d5e803b695412f9cd88ab8deba0112",
            "58fd2b9a83f94a318a8ce544a04516d5",
            "f280cbd6298b4333b62bdf271bb560f7",
            "82a15d53c7ed4fec95a49dbe08eb5322",
            "6940ec2221424003b6918ddcc38d3f9e",
            "0800dd1a62a945cca606a155e8d4f531"
          ]
        },
        "outputId": "b84a5875-7616-4460-c15e-3df46e7bf8f7"
      },
      "source": [
        "PRE_TRAINED_MODEL = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>',\n",
        "                                  pad_token='<|pad|>', additional_special_tokens=['<|sep|>','<|go|>','<|CON|>','<|PRED|>'])\n",
        "# gpt2 = GPT2Model.from_pretrained('gpt2') # must be small since ~500 MB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "917d84f3a7394f86857bea6eb84fd8dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dce69c697dbc4aea83b48fcf96e9557a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOrRgtUnblzN",
        "outputId": "504abbd4-9c19-4706-ce16-14476a43d11e"
      },
      "source": [
        "print(\"The max model length is {} for this model, although the actual embedding size for GPT small is 768\".format(tokenizer.model_max_length))\n",
        "print(\"The beginning of sequence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
        "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
        "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))\n",
        "print(\"The seperator token {} has the id {}\".format('<|sep|>',tokenizer.convert_tokens_to_ids('<|sep|>')))\n",
        "print(\"The go token {} has the id {}\".format('<|go|>',tokenizer.convert_tokens_to_ids('<|go|>')))\n",
        "print(\"The go token {} has the id {}\".format('<|CON|>',tokenizer.convert_tokens_to_ids('<|CON|>')))\n",
        "print(\"The go token {} has the id {}\".format('<|PRED|>',tokenizer.convert_tokens_to_ids('<|PRED|>')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|startoftext|> token has the id 50257\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|pad|> has the id 50258\n",
            "The seperator token <|sep|> has the id 50259\n",
            "The go token <|go|> has the id 50260\n",
            "The go token <|CON|> has the id 50261\n",
            "The go token <|PRED|> has the id 50262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNTrE6W2-QWr"
      },
      "source": [
        "#### Create Class to prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1CSLh3j_uIa"
      },
      "source": [
        "def create_label_mask(tensor,tokenizer):\n",
        "  go_id = tokenizer.convert_tokens_to_ids('<|go|>')   # -100\n",
        "  pad_id = tokenizer.convert_tokens_to_ids('<|pad|>') # -100\n",
        "  arr = tensor.numpy().copy()\n",
        "  flag = True\n",
        "  for idx, ele in enumerate(arr):\n",
        "    if ele == go_id or ele == pad_id:\n",
        "      arr[idx] = -100\n",
        "      flag = (flag != True)\n",
        "    elif flag:\n",
        "      arr[idx] = -100\n",
        "    else:\n",
        "      continue\n",
        "  return torch.tensor(arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb9KvW8NaBrw"
      },
      "source": [
        "def create_token_type_ids(tensor,tokenizer):\r\n",
        "  go_id = tokenizer.convert_tokens_to_ids('<|go|>')   # -100\r\n",
        "  eos_id = tokenizer.convert_tokens_to_ids('<|endoftext|>') # -100\r\n",
        "  arr = tensor.numpy().copy().tolist()\r\n",
        "  type_id = tokenizer.convert_tokens_to_ids('<|CON|>')\r\n",
        "  for idx, ele in enumerate(arr): # go in reverse\r\n",
        "    if ele == go_id:\r\n",
        "      arr[idx] = type_id\r\n",
        "      type_id = tokenizer.convert_tokens_to_ids('<|PRED|>')\r\n",
        "      continue\r\n",
        "    elif ele == eos_id:\r\n",
        "      arr[idx] = type_id\r\n",
        "      type_id = tokenizer.convert_tokens_to_ids('<|CON|>')\r\n",
        "      continue\r\n",
        "    arr[idx] = type_id\r\n",
        "  return torch.tensor(arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh5MxoZ6U-Mz"
      },
      "source": [
        "class GPT2Dataset(Dataset):\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768): # Max length can probably be even smaller.. pad either way..\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "    self.label_masks = []\n",
        "    self.token_type_ids = []\n",
        "    for txt in txt_list:\n",
        "      # reformat txt: x_data, y_data -> x_data\n",
        "      # ALREADY ADDED ALL SPECIAL CHARACTERS WHILE CREATING DATASET\n",
        "      # return_token_type_ids=True -> might be a way to use this for label_masking\n",
        "      encodings_dict = tokenizer(txt, truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "      temp = torch.tensor(encodings_dict['input_ids'])\n",
        "      self.input_ids.append(temp)\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "      self.label_masks.append(create_label_mask(temp,tokenizer)) # to mask everything up to and including <|go|>\n",
        "      #self.token_type_ids.append(create_label_mask(temp,tokenizer))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx],self.label_masks[idx]#,self.token_type_ids[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9eBbaXqsMv2"
      },
      "source": [
        "#### Create train and val splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8XjeBOX9woU"
      },
      "source": [
        "train_dataset = GPT2Dataset(train_text, tokenizer, max_length=210)\n",
        "val_dataset = GPT2Dataset(val_text, tokenizer, max_length=210)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMkYQHl79Dpg",
        "outputId": "802c23ed-9bbd-460c-e764-ebbc0668cb52"
      },
      "source": [
        "count = 0\n",
        "for tensor,_,_ in train_dataset: # tensor,_,_,_\n",
        "  temp = tensor.numpy().tolist()\n",
        "  for ele in temp:\n",
        "    if ele != 50258:\n",
        "      count += 1\n",
        "    else:\n",
        "      break # hit the pads\n",
        "print('The estimate of the number of tokens on average is {}'.format(count/len(train_dataset) ))\n",
        "print('The number of samples in training set is {}'.format(len(train_dataset)))\n",
        "print('The number of samples in validation set is {}'.format(len(val_dataset)))\n",
        "# 63.62543896946505 (max_len = 210. If not same number then max_length must of cut some out some)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The estimate of the number of tokens on average is 63.62543896946505\n",
            "The number of samples in training set is 63501\n",
            "The number of samples in validation set is 16451\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn3iiCvDsOiU"
      },
      "source": [
        "#### Use DataLoader to prepare for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xfwaoovrr7T"
      },
      "source": [
        "# Create the DataLoaders for our training and validation datasets.\n",
        "# We'll take training samples in random order. \n",
        "batch_size = 2\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJpCXFoXztZP"
      },
      "source": [
        "Time to load model and prepare training settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "3655df07392846be955c611fd94146c0",
            "24465b9bcc394ad884faca1203e588d3",
            "857094b2c583478abf2226e8faf2bf70",
            "249eb48faa38443b8ef54e26779bd388",
            "9b8d0cb601d54d86a263ab68d2f4a111",
            "35892c8a172240a39f4d50ccd3d43cca",
            "117d0cb0d8fb4e7687b47e2abf945b26",
            "0dd29a02dd524fcba66329dcd3872d5e",
            "f85b843e20424b28918363caae3125b5",
            "63f90ba190d44425b6d99b91aa45e4d3",
            "d8175eb5a7d14928b69a676c1868d6ea",
            "0fc2bb97427a4867bb74ca64b2f25599",
            "2537b58417e143cdb772ccb38ef1ba31",
            "9648c544629c4483b88aac73209dd36b",
            "fa3086cc29b84a479e3bb187003434ed",
            "dc5b4bea734547c4a5218d9887840f84"
          ]
        },
        "id": "UZwc0z3hzsMX",
        "outputId": "07dd7b6b-ef65-4049-8be3-4fde8dc58c2d"
      },
      "source": [
        "#configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
        "\n",
        "# instantiate the model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Needed since tokens were added to embedding matrix which is used at the input and output of the model.\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "device = torch.device(\"cuda\")\n",
        "model.cuda()\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3655df07392846be955c611fd94146c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f85b843e20424b28918363caae3125b5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib78k2e67ofU"
      },
      "source": [
        "# some parameters I cooked up that work reasonably well\n",
        "epochs = 2\n",
        "learning_rate = 5e-5\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w3Vzv6f7q2R"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdsoUluM7r90"
      },
      "source": [
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCjKLc_j_hV_"
      },
      "source": [
        "def quick_sample(data, idx):\n",
        "  temp =  data[idx].split('<|go|>')[0] + '<|go|>'\n",
        "  tensor = torch.tensor(tokenizer(temp)['input_ids'])\n",
        "  print('input:',temp)\n",
        "  print('answer:',data[idx].split('<|go|>')[-1])\n",
        "  return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwJAgn5f_d2T"
      },
      "source": [
        "def next_token(input, model, device):\n",
        "  # To try only can select tokens from input\n",
        "  model.eval()\n",
        "  token = model.forward(input_ids=input.to(device))['logits'][-1]\n",
        "  id = np.argsort(torch.nn.functional.softmax(token).cpu().detach().numpy())[-1]\n",
        "  new_input = torch.tensor(input.cpu().detach().numpy().tolist() + [id])\n",
        "  # actual token, id\n",
        "  print('predict:',tokenizer.decode(torch.tensor(id)))\n",
        "  return new_input, tokenizer.decode(torch.tensor(id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAbIQntv8Nqn"
      },
      "source": [
        "def train_epoch(model, data_loader,optimizer, device, scheduler):\n",
        "  \n",
        "  model = model.train() # Set model to training mode\n",
        "  losses = []   # keep log of loss\n",
        "  total_train_loss = 0 # Track total loss for complete batch..\n",
        "\n",
        "  for step,batch in enumerate(data_loader): # go over batches []\n",
        "    # Will need to add len(title) and date here later\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_masks = batch[1].to(device)\n",
        "    label_masks = batch[2].to(device)\n",
        "    #input_type = batch[3].to(device)\n",
        "\n",
        "    model.zero_grad() # zero gradient before prcocessing the batch\n",
        "\n",
        "    outputs = model(\n",
        "        input_ids = input_ids,\n",
        "        labels=label_masks,\n",
        "        attention_mask = attention_masks,\n",
        "        token_type_ids = None\n",
        "    )\n",
        "\n",
        "    loss = outputs[0]  \n",
        "    batch_loss = loss.item()\n",
        "    total_train_loss += batch_loss\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0) # protection from exploding gradient\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad() # Zero gradients for next batch\n",
        "    model.zero_grad() # zero gradient before prcocessing the batch\n",
        "\n",
        "    if step%500 == 0:\n",
        "      print('The current training batch loss is: {} this is step {}'.format(batch_loss, step))\n",
        "      len_validate = len(val_text) - 1 \n",
        "      tensor = quick_sample(val_text, random.randint(0, len_validate)) # randomly pickes\n",
        "      i = 0\n",
        "      while True:\n",
        "        tensor,token = next_token(tensor, model, device)\n",
        "        if token == '<|endoftext|>' or i >= 25:\n",
        "          break\n",
        "        i += 1\n",
        "      model.train()\n",
        "\n",
        "  # avg_batch_loss and total_batch_loss\n",
        "  return total_train_loss/ len(data_loader), total_train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDLcAKWYLdvp"
      },
      "source": [
        "def eval_model(model, data_loader, device):\n",
        "  \n",
        "  model = model.eval() # Set model to training mode\n",
        "\n",
        "  losses = []   # keep log of loss\n",
        "  total_train_loss = 0 # Track total loss for complete batch..\n",
        "\n",
        "  for step,batch in enumerate(data_loader): # go over batches []\n",
        "    # Will need to add len(title) and date here later\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_masks = batch[1].to(device)\n",
        "    label_masks = batch[2].to(device)\n",
        "    input_type = batch[3].to(device)\n",
        "    model.zero_grad() # zero gradient before prcocessing the batch\n",
        "\n",
        "    outputs = model(\n",
        "        input_ids = input_ids,\n",
        "        labels=label_masks,\n",
        "        attention_mask = attention_masks\n",
        "        )\n",
        "    \n",
        "    loss = outputs[0]  \n",
        "    batch_loss = loss.item()\n",
        "    total_train_loss += batch_loss\n",
        "\n",
        "    if step%100 == 0:\n",
        "      print('The current validation batch loss is: {} this is step {}'.format(batch_loss, step))\n",
        "\n",
        "  # avg_batch_loss and total_batch_loss\n",
        "  return total_train_loss/ len(data_loader), total_train_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKtmIEIKLk8S"
      },
      "source": [
        "#### Time to fine-tune the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T99fdNc9Lmj0"
      },
      "source": [
        "## Training loop\n",
        "import timeit as tt\n",
        "\n",
        "history = {} # for storing training history\n",
        "best_accuracy = 0 # store when we got best accuracy\n",
        "\n",
        "history['avg_train_loss'] = []\n",
        "history['total_train_loss'] = []\n",
        "history['avg_val_loss'] = []\n",
        "history['total_val_loss'] = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  print(\"Epoch {} of {}\".format(1 + epoch,epochs))\n",
        "  print('----------')\n",
        "  start = tt.default_timer()\n",
        "  avg_train_loss, total_train_loss = train_epoch(\n",
        "      model,\n",
        "      train_dataloader,\n",
        "      optimizer,\n",
        "      device,\n",
        "      scheduler\n",
        "  )\n",
        "  # Train loss is averaged. train accuracy is weird since first batches always worse then last.\n",
        "  print('The average train loss is {} and total train loss is {}'.format(avg_train_loss,total_train_loss))\n",
        "  stop = tt.default_timer()\n",
        "  print('It took {} seconds to train 1 epoch.'.format(stop - start))\n",
        "  \n",
        "  avg_val_loss, total_val_loss = eval_model(\n",
        "      model,\n",
        "      validation_dataloader,\n",
        "      device,\n",
        "  )\n",
        "\n",
        "  print('The average validation loss is {} and total validation loss is {}'.format(avg_val_loss, total_val_loss))\n",
        "  print('\\n')\n",
        "\n",
        "  history['avg_train_loss'].append(avg_train_loss)\n",
        "  history['total_train_loss'].append(total_train_loss)\n",
        "  history['avg_val_loss'].append(avg_val_loss)\n",
        "  history['total_val_loss'].append(total_val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5laFJAi_TpfS"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h-M0-51DkdY"
      },
      "source": [
        "torch.save(model.state_dict(),'GPT2_2_epoch_modelSEG_state.bin')\n",
        "tokenizer.save_pretrained('GPT2_2_epoch_tokenizerSEG_state.bin')\n",
        "!cp GPT2_3_epoch_model_state.bin /content/drive/MyDrive/STAT_946_Project\n",
        "!cp -r GPT2_3_epoch_tokenizer_state.bin /content/drive/MyDrive/STAT_946_Project"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}